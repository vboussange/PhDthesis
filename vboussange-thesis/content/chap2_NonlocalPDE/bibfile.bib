@article{E2020,
author = {E, Weinan and Han, Jiequn and Jentzen, Arnulf},
journal = {Nonlinearity},
title = {{Algorithms for Solving High Dimensional PDEs: From Nonlinear Monte Carlo to Machine Learning}},
  FJOURNAL = {Nonlinearity},
    VOLUME = {35},
      YEAR = {2021},
    NUMBER = {1},
     PAGES = {278--310},
      ISSN = {0951-7715},
   MRCLASS = {35K57 (35B09 35B40 35C07 35R09)},
       DOI = {10.1088/1361-6544/ac337f},
       URL = {https://doi.org/10.1088/1361-6544/ac337f},
}
@article{Han2018a,
    AUTHOR = {Han, Jiequn and Jentzen, Arnulf and E, Weinan},
     TITLE = {Solving high-dimensional partial differential equations using
              deep learning},
   JOURNAL = {Proc. Natl. Acad. Sci. USA},
  FJOURNAL = {Proceedings of the National Academy of Sciences of the United
              States of America},
    VOLUME = {115},
      YEAR = {2018},
    NUMBER = {34},
     PAGES = {8505--8510},
      ISSN = {0027-8424},
   MRCLASS = {35K55 (68T05 91A26 92C20)},
  MRNUMBER = {3847747},
       DOI = {10.1073/pnas.1718942115},
       URL = {https://doi.org/10.1073/pnas.1718942115},
}
@article{Hamel2001,
    AUTHOR = {Hamel, Fran\c{c}ois and Nadirashvili, Nikola\"{\i}},
     TITLE = {Travelling fronts and entire solutions of the {F}isher-{KPP}
              equation in {${\mathbb R}^N$}},
   JOURNAL = {Arch. Ration. Mech. Anal.},
  FJOURNAL = {Archive for Rational Mechanics and Analysis},
    VOLUME = {157},
      YEAR = {2001},
    NUMBER = {2},
     PAGES = {91--163},
      ISSN = {0003-9527},
   MRCLASS = {35K55 (35B05 35J60)},
  MRNUMBER = {1830037},
MRREVIEWER = {Vitaly A. Volpert},
       DOI = {10.1007/PL00004238},
       URL = {https://doi.org/10.1007/PL00004238},
}
@article{Perthame2007,
    AUTHOR = {Perthame, Beno\^{\i}t and G\'{e}nieys, Stephane},
     TITLE = {Concentration in the nonlocal {F}isher equation: the
              {H}amilton-{J}acobi limit},
   JOURNAL = {Math. Model. Nat. Phenom.},
  FJOURNAL = {Mathematical Modelling of Natural Phenomena},
    VOLUME = {2},
      YEAR = {2007},
    NUMBER = {4},
     PAGES = {135--151},
      ISSN = {0973-5348},
   MRCLASS = {35K57 (35F20 49L25 92C15 92D15)},
  MRNUMBER = {2447172},
       DOI = {10.1051/mmnp:2008029},
       URL = {https://doi.org/10.1051/mmnp:2008029},
}
@article{Beck2020,
author = {Beck, Christian and Hutzenthaler, Martin and Jentzen, Arnulf and Kuckuck, Benno},
year = {2020},
journal = {Revision requested from Discrete Contin. Dyn. Syst., arXiv:2012.12348},
pages = {22 pp.},
title = {An overview on deep learning-based approximation methods for partial differential equations}},
}
@article{Alfaro2016,
    AUTHOR = {Alfaro, Matthieu and Carles, R\'{e}mi},
     TITLE = {Replicator-mutator equations with quadratic fitness},
   JOURNAL = {Proc. Amer. Math. Soc.},
  FJOURNAL = {Proceedings of the American Mathematical Society},
    VOLUME = {145},
      YEAR = {2017},
    NUMBER = {12},
     PAGES = {5315--5327},
      ISSN = {0002-9939},
   MRCLASS = {92D15 (35C05 35K15 35R09 45K05)},
  MRNUMBER = {3717959},
       DOI = {10.1090/proc/13669},
       URL = {https://doi.org/10.1090/proc/13669},
}
@article{Beck2017a,
AUTHOR = {Beck, Christian and E, Weinan and Jentzen, Arnulf},
     TITLE = {Machine learning approximation algorithms for high-dimensional
              fully nonlinear partial differential equations and
              second-order backward stochastic differential equations},
   JOURNAL = {J. Nonlinear Sci.},
  FJOURNAL = {Journal of Nonlinear Science},
    VOLUME = {29},
      YEAR = {2019},
    NUMBER = {4},
     PAGES = {1563--1619},
      ISSN = {0938-8974},
   MRCLASS = {65Z05 (35K55 35R60 60H10)},
  MRNUMBER = {3993178},
       DOI = {10.1007/s00332-018-9525-3},
       URL = {https://doi.org/10.1007/s00332-018-9525-3},
}
@article{Berestycki2016,
    AUTHOR = {Berestycki, Henri and Jin, Tianling and Silvestre, Luis},
     TITLE = {Propagation in a non local reaction diffusion equation with
              spatial and genetic trait structure},
   JOURNAL = {Nonlinearity},
  FJOURNAL = {Nonlinearity},
    VOLUME = {29},
      YEAR = {2016},
    NUMBER = {4},
     PAGES = {1434--1466},
      ISSN = {0951-7715},
   MRCLASS = {35K57 (35B09 35B40 35C07 35R09)},
  MRNUMBER = {3476514},
MRREVIEWER = {Guangyu Zhao},
       DOI = {10.1088/0951-7715/29/4/1434},
       URL = {https://doi.org/10.1088/0951-7715/29/4/1434},
}
@article{Erban2007,
abstract = {A practical introduction to stochastic modelling of reaction-diffusion processes is presented. No prior knowledge of stochastic simulations is assumed. The methods are explained using illustrative examples. The article starts with the classical Gillespie algorithm for the stochastic modelling of chemical reactions. Then stochastic algorithms for modelling molecular diffusion are given. Finally, basic stochastic reaction-diffusion methods are presented. The connections between stochastic simulations and deterministic models are explained and basic mathematical tools (e.g. chemical master equation) are presented. The article concludes with an overview of more advanced methods and problems.},
archivePrefix = {arXiv},
author = {Erban, Radek and Chapman, Jonathan and Maini, Philip},
file = {:Users/victorboussange/Library/Application Support/Mendeley Desktop/Downloaded/Erban, Chapman, Maini - 2007 - A practical guide to stochastic simulations of reaction-diffusion processes.pdf:pdf},
keywords = {reaction-diffusion processes,stochastic simulations},
pages = {35 pages},
title = {A practical guide to stochastic simulations of reaction-diffusion processes},
url = {http://arxiv.org/abs/0704.1908},
year = {2007},
journal = {arXiv:0704.1908},
}
@article{Lorz2013,
    AUTHOR = {Lorz, Alexander and Lorenzi, Tommaso and Hochberg, Michael E.
              and Clairambault, Jean and Perthame, Beno\^{\i}t},
     TITLE = {Populational adaptive evolution, chemotherapeutic resistance
              and multiple anti-cancer therapies},
   JOURNAL = {ESAIM Math. Model. Numer. Anal.},
  FJOURNAL = {ESAIM. Mathematical Modelling and Numerical Analysis},
    VOLUME = {47},
      YEAR = {2013},
    NUMBER = {2},
     PAGES = {377--399},
      ISSN = {0764-583X},
   MRCLASS = {92C50 (35B25 35F20 49L25)},
  MRNUMBER = {3021691},
       DOI = {10.1051/m2an/2012031},
       URL = {https://doi.org/10.1051/m2an/2012031},
}
@article{Wang2021,
    AUTHOR = {Wang, Fang and Xue, Ling and Zhao, Kun and Zheng, Xiaoming},
     TITLE = {Global stabilization and boundary control of generalized
              {F}isher/{KPP} equation and application to diffusive {SIS}
              model},
   JOURNAL = {J. Differential Equations},
  FJOURNAL = {Journal of Differential Equations},
    VOLUME = {275},
      YEAR = {2021},
     PAGES = {391--417},
      ISSN = {0022-0396},
   MRCLASS = {35K57 (35A09 35B35 35G31)},
  MRNUMBER = {4191327},
       DOI = {10.1016/j.jde.2020.11.031},
       URL = {https://doi.org/10.1016/j.jde.2020.11.031},
}
@article{Kravvaritis2010,
abstract = {We introduce a class of infinite dimensional replicator dynamics for the study of equilibrium selection in non-cooperative games and study their properties. Examples from economic theory are provided. {\textcopyright} 2009 Elsevier Ltd. All rights reserved.},
author = {Kravvaritis, D. and Papanicolaou, V. G. and Xepapadeas, A. and Yannacopoulos, A. N.},
doi = {10.1016/j.nonrwa.2009.08.010},
file = {:Users/victorboussange/Downloads/1-s2.0-S1468121809002636-main.pdf:pdf},
issn = {14681218},
journal = {Nonlinear Analysis: Real World Applications},
keywords = {Infinite dimensional replicator dynamics,Nash equilibrium,Nonlinear partial differential equations,Steady state},
mendeley-groups = {Complexity/Project_Proposal/stochanal/game theory},
number = {4},
pages = {2537--2556},
publisher = {Elsevier Ltd},
title = {{On a class of operator equations arising in infinite dimensional replicator dynamics}},
url = {http://dx.doi.org/10.1016/j.nonrwa.2009.08.010},
volume = {11},
year = {2010}
}
@article{Kavallaris2017,
    AUTHOR = {Kavallaris, Nikos I. and Lankeit, Johannes and Winkler,
              Michael},
     TITLE = {On a degenerate nonlocal parabolic problem describing infinite
              dimensional replicator dynamics},
   JOURNAL = {SIAM J. Math. Anal.},
  FJOURNAL = {SIAM Journal on Mathematical Analysis},
    VOLUME = {49},
      YEAR = {2017},
    NUMBER = {2},
     PAGES = {954--983},
      ISSN = {0036-1410},
   MRCLASS = {35K55 (35B44 35D30 35K65 91A22)},
  MRNUMBER = {3628309},
MRREVIEWER = {Mayte P\'{e}rez-Llanos},
       DOI = {10.1137/15M1053840},
       URL = {https://doi.org/10.1137/15M1053840},
}
@article{LeCun2015,
abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
doi = {10.1038/nature14539},
file = {:Users/victorboussange/Downloads/nature14539.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
mendeley-groups = {Complexity/Project_Proposal/stochanal/deep learning - basics},
number = {7553},
pages = {436--444},
pmid = {26017442},
title = {{Deep learning}},
url = {http://www.nature.com/articles/nature14539},
volume = {521},
year = {2015}
}
@article{Bian2017,
    AUTHOR = {Bian, Shen and Chen, Li and Latos, Evangelos A.},
     TITLE = {Global existence and asymptotic behavior of solutions to a
              nonlocal {F}isher-{KPP} type problem},
   JOURNAL = {Nonlinear Anal.},
  FJOURNAL = {Nonlinear Analysis. Theory, Methods \& Applications. An
              International Multidisciplinary Journal},
    VOLUME = {149},
      YEAR = {2017},
     PAGES = {165--176},
      ISSN = {0362-546X},
   MRCLASS = {35K91 (35A01 35B40 35B44 35K20 35Q53 35R09)},
  MRNUMBER = {3575106},
       DOI = {10.1016/j.na.2016.10.017},
       URL = {https://doi.org/10.1016/j.na.2016.10.017},
}
@incollection{Coleman1994,
author = {Coleman, Sidney},
booktitle = {Bosonization},
doi = {10.1142/9789812812650_0013},
file = {:Users/victorboussange/Downloads/9789812812650_0013.pdf:pdf},
mendeley-groups = {Complexity/Project_Proposal/stochanal/examples},
pages = {128--137},
publisher = {World Scientific},
title = {{Quantum sine-Gordon equation as the massive Thirring model}},
url = {http://www.worldscientific.com/doi/abs/10.1142/9789812812650_0013},
volume = {1},
year = {1994}
}
@article{ElKaroui1997,
abstract = {We are concerned with different properties of backward stochastic differential equations and their applications to finance. These equations, first introduced by Pardoux and Peng (1990), are useful for the theory of contingent claim valuation, especially cases with constraints and for the theory of recursive utilities, introduced by Duffie and Epstein (1992a, 1992b).},
author = {{El Karoui}, N. and Peng, S. and Quenez, M. C.},
doi = {10.1111/1467-9965.00022},
file = {:Users/victorboussange/Downloads/1467-9965.00022.pdf:pdf},
issn = {0960-1627},
journal = {Mathematical Finance},
keywords = {Backward stochastic equation,Mathematical finance,Pricing,constrained portfolio,hedging portfolios,incomplete market,malliavin derivative,recursive utility,stochastic control,viscosity solution of pde},
mendeley-groups = {Complexity/Project_Proposal/stochanal/finance},
month = {jan},
number = {1},
pages = {1--71},
title = {{Backward Stochastic Differential Equations in Finance}},
url = {http://doi.wiley.com/10.1111/1467-9965.00022},
volume = {7},
year = {1997}
}
@article{Genieys2006a,
    AUTHOR = {G{\'e}nieys, S. and Volpert, V. and Auger, P.},
     TITLE = {Pattern and waves for a model in population dynamics with
              nonlocal consumption of resources},
   JOURNAL = {Math. Model. Nat. Phenom.},
  FJOURNAL = {Mathematical Modelling of Natural Phenomena},
    VOLUME = {1},
      YEAR = {2006},
    NUMBER = {1},
     PAGES = {65--82},
      ISSN = {0973-5348},
   MRCLASS = {35K57 (47G20 92D25)},
  MRNUMBER = {2318467},
       DOI = {10.1051/mmnp:2006004},
       URL = {https://doi.org/10.1051/mmnp:2006004},
}
@article{Abergel2010,
    AUTHOR = {Abergel, Frederic and Tachet, Remi},
     TITLE = {A nonlinear partial integro-differential equation from
              mathematical finance},
   JOURNAL = {Discrete Contin. Dyn. Syst.},
  FJOURNAL = {Discrete and Continuous Dynamical Systems. Series A},
    VOLUME = {27},
      YEAR = {2010},
    NUMBER = {3},
     PAGES = {907--917},
      ISSN = {1078-0947},
   MRCLASS = {35R60 (35Q91 47G20 60H15 60H30 91B70)},
  MRNUMBER = {2629564},
MRREVIEWER = {Nikita Y. Ratanov},
       DOI = {10.3934/dcds.2010.27.907},
       URL = {https://doi.org/10.3934/dcds.2010.27.907},
}
@article{zang2020weak,
title = {Weak adversarial networks for high-dimensional partial differential equations},
journal = {Journal of Computational Physics},
volume = {411},
pages = {Article No. 109409},
year = {2020},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2020.109409},
url = {https://www.sciencedirect.com/science/article/pii/S0021999120301832},
author = {Yaohua Zang and Gang Bao and Xiaojing Ye and Haomin Zhou},
keywords = {High dimensional PDE, Deep neural network, Adversarial network, Weak solution},
abstract = {Solving general high-dimensional partial differential equations (PDE) is a long-standing challenge in numerical mathematics. In this paper, we propose a novel approach to solve high-dimensional linear and nonlinear PDEs defined on arbitrary domains by leveraging their weak formulations. We convert the problem of finding the weak solution of PDEs into an operator norm minimization problem induced from the weak formulation. The weak solution and the test function in the weak formulation are then parameterized as the primal and adversarial networks respectively, which are alternately updated to approximate the optimal network parameter setting. Our approach, termed as the weak adversarial network (WAN), is fast, stable, and completely mesh-free, which is particularly suitable for high-dimensional PDEs defined on irregular domains where the classical numerical methods based on finite differences and finite elements suffer the issues of slow computation, instability and the curse of dimensionality. We apply our method to a variety of test problems with high-dimensional PDEs to demonstrate its promising performance.}
}
@article{Burger1994,
abstract = {Haldane (1937) showed that the reduction of equilibrium mean fitness in an infinite population due to recurrent deleterious mutations depends only on the mutation rate but not on the harmfulness of mutants. His analysis, as well as more recent ones (cf. Crow 1970), ignored back mutation. The purpose of the present paper is to extend these results to arbitrary mutation patterns among alleles and to quantitative genetic traits. We derive first-order approximations for the equilibrium mean fitness (and the mutation load) and determine the order of the error term. For a metric trait under mutation-stabilizing-selection balance our result differs qualitatively from that of Crow and Kimura (1964), whose analysis is based on a Gaussian assumption. Our general approach also yields a mathematical proof that the variance under the usual mutation-stabilizing-selection model is, to first order, µ/s (the house-of-cards approximation) as µ/s tends to zero. This holds for arbitrary mutant distributions and does not require that the population mean coincide with the optimum. We show how the mutant distribution determines the order of the error term, and thus the accuracy of the house-of-cards approximation. Upper and lower bounds to the equilibrium variance are derived that deviate only to second order as µ/s tends to zero. The multilocus case is treated under the assumption of global linkage equilibrium. {\textcopyright} 1994, Springer-Verlag. All rights reserved.},
author = {Burger, Reinhard and Hofbauer, Josef},
doi = {10.1007/BF00163878},
file = {:Users/victorboussange/Downloads/B{\~{A}}¼rger-Hofbauer1994_Article_MutationLoadAndMutation-select.pdf:pdf},
issn = {0303-6812},
journal = {J. Math. Biol.},
fjournal = {Journal of Mathematical Biology},
keywords = {Mutation,Mutation load,Quantitative genetic traits,Selection},
mendeley-groups = {Complexity/Project_Proposal/stochanal/biology},
number = {3},
pages = {193--218},
pmid = {8182355},
title = {{Mutation load and mutation-selection-balance in quantitative genetic traits}},
url = {http://link.springer.com/10.1007/BF00163878},
volume = {32},
year = {1994}
}
@incollection{Sunderasan2020,
abstract = {Mycotoxins are small (MW approximately 700), toxic chemical products formed as secondary metabolites by a few fungal species that readily colonise crops and contaminate them with toxins in the field or after harvest. Ochratoxins and Aflatoxins are mycotoxins of major significance and hence there has been significant research on broad range of analytical and detection techniques that could be useful and practical. Due to the variety of structures of these toxins, it is impossible to use one standard technique for analysis and/or detection. Practical requirements for high-sensitivity analysis and the need for a specialist laboratory setting create challenges for routine analysis. Several existing analytical techniques, which offer flexible and broad-based methods of analysis and in some cases detection, have been discussed in this manuscript. There are a number of methods used, of which many are lab-based, but to our knowledge there seems to be no single technique that stands out above the rest, although analytical liquid chromatography, commonly linked with mass spectroscopy is likely to be popular. This review manuscript discusses (a) sample pre-treatment methods such as liquid-liquid extraction (LLE), supercritical fluid extraction (SFE), solid phase extraction (SPE), (b) separation methods such as (TLC), high performance liquid chromatography (HPLC), gas chromatography (GC), and capillary electrophoresis (CE) and (c) others such as ELISA. Further currents trends, advantages and disadvantages and future prospects of these methods have been discussed.},
author = {Sunderasan, Srinivasan},
booktitle = {Long-Term Investments},
doi = {10.4324/9780367817909-3},
file = {:Users/victorboussange/Downloads/2013_Book_FinancialModeling.pdf:pdf},
isbn = {9783642371127},
mendeley-groups = {Complexity/Project_Proposal/stochanal/finance},
pages = {33--51},
publisher = {Routledge India},
title = {{Financial Modeling}},
url = {https://www.taylorfrancis.com/books/9781000087338/chapters/10.4324/9780367817909-3},
year = {2020}
}
@article{Caglioti1992,
    AUTHOR = {Caglioti, E. and Lions, P.-L. and Marchioro, C. and
              Pulvirenti, M.},
     TITLE = {A special class of stationary flows for two-dimensional
              {E}uler equations: a statistical mechanics description. {II}},
   JOURNAL = {Comm. Math. Phys.},
  FJOURNAL = {Communications in Mathematical Physics},
    VOLUME = {174},
      YEAR = {1995},
    NUMBER = {2},
     PAGES = {229--260},
      ISSN = {0010-3616},
   MRCLASS = {82C40 (35Q30 76F99 76M99 82B40)},
  MRNUMBER = {1362165},
MRREVIEWER = {Boguslaw Zegarlinski},
       URL = {http://projecteuclid.org/euclid.cmp/1104275293},
}
@article{Berner2020,
abstract = {We present a deep learning algorithm for the numerical solution of parametric families of high-dimensional linear Kolmogorov partial differential equations (PDEs). Our method is based on reformulating the numerical approximation of a whole family of Kolmogorov PDEs as a single statistical learning problem using the Feynman-Kac formula. Successful numerical experiments are presented, which empirically confirm the functionality and efficiency of our proposed algorithm in the case of heat equations and Black-Scholes option pricing models parametrized by affine-linear coefficient functions. We show that a single deep neural network trained on simulated data is capable of learning the solution functions of an entire family of PDEs on a full space-time region. Most notably, our numerical observations and theoretical results also demonstrate that the proposed method does not suffer from the curse of dimensionality, distinguishing it from almost all standard numerical methods for PDEs.},
archivePrefix = {arXiv},
arxivId = {2011.04602},
author = {Berner, Julius and Dablander, Markus and Grohs, Philipp},
file = {:Users/victorboussange/Downloads/2011.04602.pdf:pdf},
journal = {arXiv:2011.04602},
mendeley-groups = {Complexity/Project_Proposal/stochanal},
title = {{Numerically Solving Parametric Families of High-Dimensional Kolmogorov Partial Differential Equations via Deep Learning}},
url = {http://arxiv.org/abs/2011.04602},
year = {2020},
pages = {22 pages}
}
@article{Lacey1995,
    AUTHOR = {Lacey, A. A.},
     TITLE = {Thermal runaway in a non-local problem modelling {O}hmic
              heating. {I}. {M}odel derivation and some special cases},
   JOURNAL = {European J. Appl. Math.},
  FJOURNAL = {European Journal of Applied Mathematics},
    VOLUME = {6},
      YEAR = {1995},
    NUMBER = {2},
     PAGES = {127--144},
      ISSN = {0956-7925},
   MRCLASS = {80A20 (35K55)},
  MRNUMBER = {1331495},
MRREVIEWER = {Kuppalapalle Vajravelu},
       DOI = {10.1017/S095679250000173X},
       URL = {https://doi.org/10.1017/S095679250000173X},
}
@article{E2017,
abstract = {We propose a new algorithm for solving parabolic partial differential equations (PDEs) and backward stochastic differential equations (BSDEs) in high dimension, by making an analogy between the BSDE and reinforcement learning with the gradient of the solution playing the role of the policy function, and the loss function given by the error between the prescribed terminal condition and the solution of the BSDE. The policy function is then approximated by a neural network, as is done in deep reinforcement learning. Numerical results using TensorFlow illustrate the efficiency and accuracy of the proposed algorithms for several 100-dimensional nonlinear PDEs from physics and finance such as the Allen-Cahn equation, the Hamilton-Jacobi-Bellman equation, and a nonlinear pricing model for financial derivatives.},
author = {E, Weinan and Han, Jiequn and Jentzen, Arnulf},
doi = {10.1007/s40304-017-0117-6},
file = {:Users/victorboussange/Library/Application Support/Mendeley Desktop/Downloaded/E, Han, Jentzen - 2017 - Deep Learning-Based Numerical Methods for High-Dimensional Parabolic Partial Differential Equations and Backwar.pdf:pdf},
issn = {2194-6701},
journal = {Communications in Mathematics and Statistics},
keywords = {Backward stochastic differential equations,Control,Deep learning,Feynman-Kac,High dimension,PDEs},
mendeley-groups = {Complexity/Project_Proposal/stochanal},
month = {dec},
number = {4},
pages = {349--380},
publisher = {Springer Berlin Heidelberg},
title = {{Deep Learning-Based Numerical Methods for High-Dimensional Parabolic Partial Differential Equations and Backward Stochastic Differential Equations}},
url = {http://link.springer.com/10.1007/s40304-017-0117-6},
volume = {5},
year = {2017}
}
@article{Barone1971,
author = {Barone, A. and Esposito, F. and Magee, C. J. and Scott, A. C.},
doi = {10.1007/BF02820622},
file = {:Users/victorboussange/Downloads/Barone1971_Article_TheoryAndApplicationsOfTheSine.pdf:pdf},
issn = {1826-9850},
journal = {La Rivista del Nuovo Cimento},
mendeley-groups = {Complexity/Project_Proposal/stochanal/examples},
number = {2},
pages = {227--267},
title = {Theory and applications of the sine-{G}ordon equation},
url = {http://link.springer.com/10.1007/BF02820622},
volume = {1},
year = {1971}
}
@book{Pham2009,
    AUTHOR = {Pham, Huy\^{e}n},
     TITLE = {Continuous-time stochastic control and optimization with
              financial applications},
    SERIES = {Stochastic Modelling and Applied Probability},
    VOLUME = {61},
 PUBLISHER = {Springer-Verlag, Berlin},
      YEAR = {2009},
     PAGES = {xviii+232},
      ISBN = {978-3-540-89499-5},
   MRCLASS = {49K45 (49-02 60H10 60H30 91G80 93E20)},
  MRNUMBER = {2533355},
       DOI = {10.1007/978-3-540-89500-8},
       URL = {https://doi.org/10.1007/978-3-540-89500-8},
}
@article{Hairer2016,
    AUTHOR = {Hairer, Martin and Shen, Hao},
     TITLE = {The dynamical sine-{G}ordon model},
   JOURNAL = {Comm. Math. Phys.},
  FJOURNAL = {Communications in Mathematical Physics},
    VOLUME = {341},
      YEAR = {2016},
    NUMBER = {3},
     PAGES = {933--989},
      ISSN = {0010-3616},
   MRCLASS = {60H15 (35K58 35R60 37H10)},
  MRNUMBER = {3452276},
MRREVIEWER = {Dirk Bl\"{o}mker},
       DOI = {10.1007/s00220-015-2525-3},
       URL = {https://doi.org/10.1007/s00220-015-2525-3},
}
@article {Beck2019,
    AUTHOR = {Beck, Christian and Becker, Sebastian and Cheridito, Patrick
              and Jentzen, Arnulf and Neufeld, Ariel},
     TITLE = {Deep splitting method for parabolic {PDE}s},
   JOURNAL = {SIAM J. Sci. Comput.},
  FJOURNAL = {SIAM Journal on Scientific Computing},
    VOLUME = {43},
      YEAR = {2021},
    NUMBER = {5},
     PAGES = {A3135--A3154},
      ISSN = {1064-8275},
   MRCLASS = {65M22 (35K15 91G20 93E20)},
  MRNUMBER = {4310910},
       DOI = {10.1137/19M1297919},
       URL = {https://doi.org/10.1137/19M1297919},
}

@Article{becker2020numerical,
author = {Becker, Sebastian and Braunwarth, Ramon and Hutzenthaler, Martin and Jentzen, Arnulf and von Wurstemberger, Philippe},
title = {Numerical Simulations for Full History Recursive Multilevel {P}icard Approximations for Systems of High-Dimensional Partial Differential Equations},
fjournal = {Communications in Computational Physics},
journal = {Commun. Comput. Phys.},
year = {2020},
volume = {28},
number = {5},
pages = {2109--2138},
issn = {1991-7120},
doi = {https://doi.org/10.4208/cicp.OA-2020-0130},
url = {http://global-sci.org/intro/article_detail/cicp/18406.html}
}                    
@article{Maire2012,
abstract = {We introduce Monte Carlo methods to compute the solution of elliptic equations with pure Neumann boundary conditions. We first prove that the solution obtained by the stochastic representation has a zero mean value with respect to the invariant measure of the stochastic process associated to the equation. Pointwise approximations are computed by means of standard and new simulation schemes especially devised for local time approximation on the boundary of the domain. Global approximations are computed thanks to a stochastic spectral formulation taking into account the property of zero mean value of the solution. This stochastic formulation is asymptotically perfect in terms of conditioning. Numerical examples are given on the Laplace operator on a square domain with both pure Neumann and mixed Dirichlet-Neumann boundary conditions. A more general convection-diffusion equation is also numerically studied.},
archivePrefix = {arXiv},
arxivId = {1203.4910},
author = {Maire, Sylvain and Tanr{\'{e}}, Etienne},
doi = {10.1515/mcma-2013-0010},
eprint = {1203.4910},
file = {:Users/victorboussange/Library/Application Support/Mendeley Desktop/Downloaded/Maire, Tanr{\'{e}} - 2012 - Monte Carlo approximations of the Neumann problem.pdf:pdf},
issn = {0929-9629},
journal = {Monte Carlo Methods and Applications},
mendeley-groups = {Complexity/Project_Proposal/stochanal},
number = {3 pages},
title = {{Monte Carlo approximations of the Neumann problem}},
url = {https://www.degruyter.com/view/j/mcma.2013.19.issue-3/mcma-2013-0010/mcma-2013-0010.xml http://arxiv.org/abs/1203.4910},
volume = {19},
year = {2012}
}
@article{Berestycki2009b,
    AUTHOR = {Berestycki, Henri and Nadin, Gr\'{e}goire and Perthame, Benoit and
              Ryzhik, Lenya},
     TITLE = {The non-local {F}isher-{KPP} equation: travelling waves and
              steady states},
   JOURNAL = {Nonlinearity},
  FJOURNAL = {Nonlinearity},
    VOLUME = {22},
      YEAR = {2009},
    NUMBER = {12},
     PAGES = {2813--2844},
      ISSN = {0951-7715},
   MRCLASS = {35Q53 (35C07)},
  MRNUMBER = {2557449},
       DOI = {10.1088/0951-7715/22/12/002},
       URL = {https://doi.org/10.1088/0951-7715/22/12/002},
}
@article{Amadori2003,
abstract = {A class of nonlinear integro-differential Cauchy problems is studied by means of the viscosity solutions approach. In view of financial applications, we are interested in continuous initial data with exponential growth at infinity. Existence and uniqueness of solution is obtained through Perron's method, via a comparison principle; besides, a first order regularity result is given. This extension of the standard theory of viscosity solutions allows to price derivatives in jump–diffusion markets with correlated assets, even in the presence of a large investor, by means of the PDE's approach. In particular, derivatives may be perfectly hedged in a completed market.},
author = {Amadori, Anna Lisa},
file = {:Users/victorboussange/Downloads/1356060597.pdf:pdf},
issn = {0893-4983},
journal = {Differential Integral Equations},
fjournal = {Differential and Integral Equations},
keywords = {35B30,35K55,35R10,60J75,91B24,91B26},
mendeley-groups = {Complexity/Project_Proposal/stochanal/finance},
number = {7},
pages = {787--811},
title = {{Nonlinear integro-differential evolution problems arising in option pricing: a viscosity solutions approach}},
volume = {16},
year = {2003}
}
@article{Chan1999,
    AUTHOR = {Chan, Terence},
     TITLE = {Pricing contingent claims on stocks driven by {L}\'{e}vy
              processes},
   JOURNAL = {Ann. Appl. Probab.},
  FJOURNAL = {The Annals of Applied Probability},
    VOLUME = {9},
      YEAR = {1999},
    NUMBER = {2},
     PAGES = {504--528},
      ISSN = {1050-5164},
   MRCLASS = {91B28},
  MRNUMBER = {1687394},
MRREVIEWER = {R\"{u}diger Kiesel},
       DOI = {10.1214/aoap/1029962753},
       URL = {https://doi.org/10.1214/aoap/1029962753},
}
@article{Chen,
    AUTHOR = {Chen, C.-K. and Fife, P. C.},
     TITLE = {Nonlocal models of phase transitions in solids},
   JOURNAL = {Adv. Math. Sci. Appl.},
  FJOURNAL = {Advances in Mathematical Sciences and Applications},
    VOLUME = {10},
      YEAR = {2000},
    NUMBER = {2},
     PAGES = {821--849},
      ISSN = {1343-4373},
   MRCLASS = {74F05 (74N20 80A22)},
  MRNUMBER = {1807453},
}
@article{Gajewski2003,
    AUTHOR = {Gajewski, Herbert and Zacharias, Klaus},
     TITLE = {On a nonlocal phase separation model},
   JOURNAL = {J. Math. Anal. Appl.},
  FJOURNAL = {Journal of Mathematical Analysis and Applications},
    VOLUME = {286},
      YEAR = {2003},
    NUMBER = {1},
     PAGES = {11--31},
      ISSN = {0022-247X},
   MRCLASS = {35K55 (35A15 35R10 80A22)},
  MRNUMBER = {2009615},
MRREVIEWER = {Matthias Wilhelm Winter},
       DOI = {10.1016/S0022-247X(02)00425-0},
       URL = {https://doi.org/10.1016/S0022-247X(02)00425-0},
}
@article{Kingma2014,
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
archivePrefix = {arXiv},
arxivId = {1412.6980},
author = {Kingma, Diederik P. and Ba, Jimmy},
eprint = {1412.6980},
file = {:Users/victorboussange/Library/Application Support/Mendeley Desktop/Downloaded/Kingma, Ba - 2014 - Adam A Method for Stochastic Optimization.pdf:pdf},
mendeley-groups = {Complexity/Project_Proposal/stochanal},
pages = {15 pp.},
title = {{Adam: A Method for Stochastic Optimization}},
url = {http://arxiv.org/abs/1412.6980},
year = {2014},
journal = {arXiv:1412.6980},
}

@article{gonon2021deep,
  doi = {10.48550/ARXIV.2102.11707},
  url = {https://arxiv.org/abs/2102.11707},
  author = {Gonon, Lukas and Schwab, Christoph},
  keywords = {Numerical Analysis (math.NA), Probability (math.PR), FOS: Mathematics, FOS: Mathematics},
  title = {Deep {ReLU} neural networks overcome the curse of dimensionality for partial integrodifferential equations},
  publisher = {arXiv},
  year = {2021},
  pages = {35 pp.},
  archivePrefix={arXiv},
  arxivId={2102.11707},
  ePrint={2102.11707},
  journal={arXiv:2102.11707},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{heinrich1998monte,
  title={{Monte Carlo} complexity of global solution of integral equations},
  author={Heinrich, Stefan},
  journal={J. Complex.},
  fjournal={Journal of Complexity},
  volume={14},
  number={2},
  pages={151--175},
  year={1998},
  publisher={Elsevier}
}

@article{heinrich1999monte,
  title={{Monte Carlo} complexity of parametric integration},
  author={Heinrich, Stefan and Sindambiwe, Eug{\`e}ne},
  journal={J. Complex.},
  fjournal={Journal of Complexity},
  volume={15},
  number={3},
  pages={317--341},
  year={1999},
  publisher={Elsevier}
}

@article{grohs2021proof,
  doi = {10.48550/ARXIV.2104.02746},
  url = {https://arxiv.org/abs/2104.02746},
  author = {Grohs, Philipp and Voigtlaender, Felix},
  keywords = {Machine Learning (cs.LG), Functional Analysis (math.FA), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics, 41A46, 68T07, 41A65, 41A25, 68T05, 65Y20},
  title = {Proof of the Theory-to-Practice Gap in Deep Learning via Sampling Complexity bounds for Neural Network Approximation Spaces},
  publisher = {arXiv},
  year = {2021},
  pages = {42 pp.},
  archivePrefix={arXiv},
  arxivId={2104.02746},
  ePrint={2104.02746},
  journal={arXiv:2104.02746},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{WangPerdikaris2020,
title = "Deep learning of free boundary and {S}tefan problems",
   JOURNAL = {J. Comput. Phys.},
  FJOURNAL = {Journal of Computational Physics},
pages = "Article No. 109914, 27 pp.",
year = "2020",
issn = "0021-9991",
doi = "https://doi.org/10.1016/j.jcp.2020.109914",
author = "Sifan Wang and Paris Perdikaris",
keywords = "Keywords Physics-informed neural networks, Phase transitions, Partial differential equations, Scientific machine learning",
abstract = "Free boundary problems appear naturally in numerous areas of mathematics, science and engineering. These problems present a great computational challenge because they necessitate numerical methods that can yield an accurate approximation of free boundaries and complex dynamic interfaces. In this work, we propose a multi-network model based on physics-informed neural networks to tackle a general class of forward and inverse free boundary problems called Stefan problems. Specifically, we approximate the unknown solution as well as any moving boundaries by two deep neural networks. Besides, we formulate a new type of inverse Stefan problems that aim to reconstruct the solution and free boundaries directly from sparse and noisy measurements. We demonstrate the effectiveness of our approach in a series of benchmarks spanning different types of Stefan problems, and illustrate how the proposed framework can accurately recover solutions of partial differential equations with moving boundaries and dynamic interfaces. All code and data accompanying this manuscript are publicly available at https://github.com/PredictiveIntelligenceLab/DeepStefan."
}

@article{Cruz2020,
    AUTHOR = {Cruz, Jos\'{e} M. T. S. and \v{S}ev\v{c}ovi\v{c}, Daniel},
     TITLE = {On solutions of a partial integro-differential equation in
              {B}essel potential spaces with applications in option pricing
              models},
   JOURNAL = {Jpn. J. Ind. Appl. Math.},
  FJOURNAL = {Japan Journal of Industrial and Applied Mathematics},
    VOLUME = {37},
      YEAR = {2020},
    NUMBER = {3},
     PAGES = {697--721},
      ISSN = {0916-7005},
   MRCLASS = {45K05 (34G20 35K58 35R09 91G20)},
  MRNUMBER = {4142255},
MRREVIEWER = {Lina Song},
       DOI = {10.1007/s13160-020-00414-2},
       URL = {https://doi.org/10.1007/s13160-020-00414-2},
}
@article{Hamel2020,
    AUTHOR = {Hamel, F. and Lavigne, F. and Martin, G. and Roques, L.},
     TITLE = {Dynamics of adaptation in an anisotropic phenotype-fitness
              landscape},
   JOURNAL = {Nonlinear Anal. Real World Appl.},
  FJOURNAL = {Nonlinear Analysis. Real World Applications. An International
              Multidisciplinary Journal},
    VOLUME = {54},
      YEAR = {2020},
     PAGES = {Article No. 103107, 33 pp.},
      ISSN = {1468-1218},
   MRCLASS = {92D15 (35K55 35Q92 37N25)},
  MRNUMBER = {4062543},
       DOI = {10.1016/j.nonrwa.2020.103107},
       URL = {https://doi.org/10.1016/j.nonrwa.2020.103107},
}
@article{Kolluru2019,
abstract = {A Neural Network (NN) based numerical method is formulated and implemented for solving Boundary Value Problems (BVPs) and numerical results are presented to validate this method by solving Laplace equation with Dirichlet boundary condition and Poisson's equation with mixed boundary conditions. The principal advantage of NN based numerical method is the discrete data points where the field is computed, can be unstructured and do not suffer from issues of meshing like traditional numerical methods such as Finite Difference Time Domain or Finite Element Method. Numerical investigations are carried out for both uniform and non-uniform training grid distributions to understand the efficacy and limitations of this method and to provide qualitative understanding of various parameters involved.},
archivePrefix = {arXiv},
arxivId = {1909.11082},
author = {Kolluru, Sethu Hareesh},
eprint = {1909.11082},
file = {:Users/victorboussange/Library/Application Support/Mendeley Desktop/Downloaded/Kolluru - 2019 - A Neural Network Based Method to Solve Boundary Value Problems.pdf:pdf},
mendeley-groups = {Complexity/Project_Proposal/stochanal},
title = {{A Neural Network Based Method to Solve Boundary Value Problems}},
url = {http://arxiv.org/abs/1909.11082},
year = {2019},
journal = {arXiv:1909.11082},
pages = {9 pp.}
}
@article{Chen2020,
abstract = {We provide a review of recent advancements in non-local continuous models for migration, mainly from the perspective of its involvement in embryonal development and cancer invasion. Particular emphasis is placed on spatial non-locality occurring in advection terms, used to characterize a cell's motility bias according to its interactions with other cellular and acellular components in its vicinity (e.g. cell–cell and cell–tissue adhesions, non-local chemotaxis), but we also briefly address spatially non-local source terms. Following a short introduction and description of applications, we give a systematic classification of available PDE models with respect to the type of featured non-localities and review some of the mathematical challenges arising from such models, with a focus on analytical aspects.},
archivePrefix = {arXiv},
arxivId = {1911.05200},
author = {Chen, Li and Painter, Kevin and Surulescu, Christina and Zhigun, Anna},
doi = {10.1098/rstb.2019.0379},
eprint = {1911.05200},
file = {:Users/victorboussange/Downloads/rstb.2019.0379.pdf:pdf},
isbn = {0000000332736},
issn = {0962-8436},
journal = {Philos. Trans. Roy. Soc. B},
fjournal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
keywords = {Cell-cell and cell-tissue adhesion,Classes of nonlocal models,Haptotaxis,Integro-differential equations,Mathematical challenges,Nonlocal and local chemotaxis},
mendeley-groups = {Complexity/Project_Proposal/stochanal/intro},
number = {1807},
pages = {Article No. 20190379, 9 pp.},
title = {{Mathematical models for cell migration: a non-local perspective}},
url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0379},
volume = {375},
year = {2020}
}
@article{Hutzenthaler2018,
abstract = {For a long time it is well-known that high-dimensional linear parabolic partial differential equations (PDEs) can be approximated by Monte Carlo methods with a computational effort which grows polynomially both in the dimension and in the reciprocal of the prescribed accuracy. In other words, linear PDEs do not suffer from the curse of dimensionality. For general semilinear PDEs with Lipschitz coefficients, however, it remained an open question whether these suffer from the curse of dimensionality. In this paper we partially solve this open problem. More precisely, we prove in the case of semilinear heat equations with gradient-independent and globally Lipschitz continuous nonlinearities that the computational effort of a variant of the recently introduced multilevel Picard approximations grows polynomially both in the dimension and in the reciprocal of the required accuracy.},
archivePrefix = {arXiv},
arxivId = {1807.01212},
author = {Hutzenthaler, Martin and Jentzen, Arnulf and Kruse, Thomas and Nguyen, Tuan Anh and von Wurstemberger, Philippe},
eprint = {1807.01212},
file = {:Users/victorboussange/Library/Application Support/Mendeley Desktop/Downloaded/Hutzenthaler et al. - 2018 - Overcoming the curse of dimensionality in the numerical approximation of semilinear parabolic partial diffe.pdf:pdf},
mendeley-groups = {Complexity/Project_Proposal/stochanal},
pages = {30 pages},
title = {{Overcoming the curse of dimensionality in the numerical approximation of semilinear parabolic partial differential equations}},
url = {http://arxiv.org/abs/1807.01212},
year = {2018},
journal = {arXiv:1807.01212}
}
@article{Hirsa2020,
abstract = {We investigate solving partial integro-differential equations (PIDEs) using unsupervised deep learning in this paper. To price options, assuming underlying processes follow Levy processes, we require to solve PIDEs. In supervised deep learning, pre-calculated labels are used to train neural networks to fit the solution of the PIDE. In an unsupervised deep learning, neural networks are employed as the solution, and the derivatives and the integrals in the PIDE are calculated based on the neural network. By matching the PIDE and its boundary conditions, the neural network gives an accurate solution of the PIDE. Once trained, it would be fast for calculating options values as well as option Greeks.},
archivePrefix = {arXiv},
arxivId = {2006.15012},
author = {Hirsa, Ali and Fu, Weilong},
eprint = {2006.15012},
file = {:Users/victorboussange/Downloads/2006.15012.pdf:pdf},
issn = {23318422},
journal = {arXiv:2006.15012}},
keywords = {Deep learning,Neural networks,PIDEs},
mendeley-groups = {Complexity/Project_Proposal/stochanal/intro},
pages = {22 pages},
title = {{An unsupervised deep learning approach in solving partial integro-differential equations}},
url = {http://arxiv.org/abs/2006.15012},
year = {2020}
}
@article{Laing2003,
abstract = {We develop partial differential equation (PDE) methods to study the dynamics of pattern formation in partial integro-differential equations (PIDEs) defined on a spatially extended domain. Our primary focus is on scalar equations in two spatial dimensions. These models arise in a variety of neuronal modeling problems and also occur in material science. We first derive a PDE which is equivalent to the PIDE. We then find circularly symmetric solutions of the resultant PDE; the linearization of the PDE around these solutions provides a criterion for their stability. When a solution is unstable, our analysis predicts the exact number of peaks that form to comprise a multipeak solution of the full PDE. We illustrate our results with specific numerical examples and discuss other systems for which this technique can be used.},
author = {Laing, Carlo R. and Troy, William C.},
doi = {10.1137/030600040},
file = {:Users/victorboussange/Downloads/030600040.pdf:pdf},
issn = {1536-0040},
journal = {SIAM Journal on Applied Dynamical Systems},
keywords = {Integro-differential equation,Nonlocal,PDE,Pattern formation},
mendeley-groups = {Complexity/Project_Proposal/stochanal/intro},
month = {jan},
number = {3},
pages = {487--516},
title = {{PDE Methods for Nonlocal Models}},
url = {http://epubs.siam.org/doi/10.1137/030600040},
volume = {2},
year = {2003}
}
@article{Merton1976,
abstract = {The validity of the classic Black-Scholes option pricing formula dcpcnds on the capability of investors to follow a dynamic portfolio strategy in the stock that replicates the payoff structure to the option. The critical assumption required for such a strategy to be feasible, is that the underlying stock return dynamics can be described by a stochastic process with a continuous sample path. In this paper, an option pricing formula is derived for the more-general cast when the underlying stock returns are gcncrated by a mixture of both continuous and jump processes. The derived formula has most of the attractive features of the original Black&holes formula in that it does not dcpcnd on investor prcfcrenccs or knowledge of the expcctsd return on the underlying stock. Morcover, the same analysis applied to the options can bc extcndcd to the pricingofcorporatc liabilities.},
author = {Merton, Robert C.},
doi = {10.1016/0304-405X(76)90022-2},
file = {:Users/victorboussange/Downloads/1-s2.0-0304405X76900222-main.pdf:pdf},
issn = {0304405X},
journal = {J. Financ. Econ.},
mendeley-groups = {Complexity/Project_Proposal/stochanal,Complexity/Project_Proposal/stochanal/finance},
number = {1--2},
pages = {125--144},
title = {{Option pricing when underlying stock returns are discontinuous}},
url = {https://linkinghub.elsevier.com/retrieve/pii/0304405X76900222},
volume = {3},
year = {1976}
}
@article{Blechschmidt2021,
abstract = {Neural networks are increasingly used to construct numerical solution methods for partial differential equations. In this expository review, we introduce and contrast three important recent approaches attractive in their simplicity and their suitability for high-dimensional problems: physics-informed neural networks, methods based on the Feynman-Kac formula and the Deep BSDE solver. The article is accompanied by a suite of expository software in the form of Jupyter notebooks in which each basic methodology is explained step by step, allowing for a quick assimilation and experimentation. An extensive bibliography summarizes the state of the art.},
archivePrefix = {arXiv},
arxivId = {2102.11802},
author = {Blechschmidt, Jan and Ernst, Oliver G.},
eprint = {2102.11802},
file = {:Users/victorboussange/Downloads/2102.11802.pdf:pdf},
keywords = {backward differential equation,curse of dimensional-,feynman-kac,hamilton-jacobi-bellman equations,ity,neural networks,partial differential equation,stochastic process},
mendeley-groups = {Complexity/Project_Proposal/stochanal},
title = {{Three Ways to Solve Partial Differential Equations with Neural Networks -- A Review}},
url = {http://arxiv.org/abs/2102.11802},
year = {2021},
journal = {arXiv:2102.11802},
pages = {32 pages}
}
@article{Chen2018,
abstract = {We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a black-box differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.},
author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
pages = {60 pages},
title = {{Neural Ordinary Differential Equations}},
url = {http://arxiv.org/abs/1806.07366},
year = {2018},
journal = {arXiv:1806.07366}
}
@article{Cantarutti2020,
author = {Cantarutti, Nicola},
doi = {10.2139/ssrn.3579408},
file = {:Users/victorboussange/Downloads/SSRN-id3579408.pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
keywords = {evy processes,finite difference method,l,merton model,option pricing,pide},
mendeley-groups = {Complexity/Project_Proposal/stochanal},
number = {4 pages},
title = {{Numerical Study of the Merton PIDE in Option Pricing}},
url = {https://www.ssrn.com/abstract=3579408},
year = {2020}
}
@article{Rackauckas2020,
abstract = {In the context of science, the well-known adage "a picture is worth a thousand words" might well be "a model is worth a thousand datasets." Scientific models, such as Newtonian physics or biological gene regulatory networks, are human-driven simplifications of complex phenomena that serve as surrogates for the countless experiments that validated the models. Recently, machine learning has been able to overcome the inaccuracies of approximate modeling by directly learning the entire set of nonlinear interactions from data. However, without any predetermined structure from the scientific basis behind the problem, machine learning approaches are flexible but data-expensive, requiring large databases of homogeneous labeled training data. A central challenge is reconciling data that is at odds with simplified models without requiring "big data". In this work we develop a new methodology, universal differential equations (UDEs), which augments scientific models with machine-learnable structures for scientifically-based learning. We show how UDEs can be utilized to discover previously unknown governing equations, accurately extrapolate beyond the original data, and accelerate model simulation, all in a time and data-efficient manner. This advance is coupled with open-source software that allows for training UDEs which incorporate physical constraints, delayed interactions, implicitly-defined events, and intrinsic stochasticity in the model. Our examples show how a diverse set of computationally-difficult modeling issues across scientific disciplines, from automatically discovering biological mechanisms to accelerating climate simulations by 15,000x, can be handled by training UDEs.},
author = {Rackauckas, Christopher and Ma, Yingbo and Martensen, Julius and Warner, Collin and Zubov, Kirill and Supekar, Rohit and Skinner, Dominic and Ramadhan, Ali},
file = {:Users/victorboussange/Library/Application Support/Mendeley Desktop/Downloaded/Rackauckas et al. - 2020 - Universal Differential Equations for Scientific Machine Learning(4).pdf:pdf},
journal = {arXiv:2001.04385v3},
pages = {18 pages},
title = {{Universal Differential Equations for Scientific Machine Learning}},
url = {http://arxiv.org/abs/2001.04385},
year = {2020}
}
@article{Becker2019,
abstract = {Nowadays many financial derivatives which are traded on stock and futures exchanges, such as American or Bermudan options, are of early exercise type. Often the pricing of early exercise options gives rise to high-dimensional optimal stopping problems, since the dimension corresponds to the number of underlyings in the associated hedging portfolio. High-dimensional optimal stopping problems are, however, notoriously difficult to solve due to the well-known curse of dimensionality. In this work we propose an algorithm for solving such problems, which is based on deep learning and computes, in the context of early exercise option pricing, both approximations for an optimal exercise strategy and the price of the considered option. The proposed algorithm can also be applied to optimal stopping problems that arise in other areas where the underlying stochastic process can be efficiently simulated. We present numerical results for a large number of example problems, which include the pricing of many high-dimensional American and Bermudan options such as, for example, Bermudan max-call options in up to 5000 dimensions. Most of the obtained results are compared to reference values computed by exploiting the specific problem design or, where available, to reference values from the literature. These numerical results suggest that the proposed algorithm is highly effective in the case of many underlyings, in terms of both accuracy and speed.},
archivePrefix = {arXiv},
arxivId = {1908.01602},
author = {Becker, Sebastian and Cheridito, Patrick and Jentzen, Arnulf and Welti, Timo},
eprint = {1908.01602},
file = {:Users/victorboussange/Library/Application Support/Mendeley Desktop/Downloaded/Becker et al. - 2019 - Solving high-dimensional optimal stopping problems using deep learning.pdf:pdf},
keywords = {american option,bermudan option,curse of dimensionality,deep learning,derivative pricing,financial derivative,optimal stopping,option pricing},
mendeley-groups = {Complexity/Project_Proposal/stochanal},
pages = {42 pages},
title = {{Solving high-dimensional optimal stopping problems using deep learning}},
url = {http://arxiv.org/abs/1908.01602},
year = {2019},
journal = {Minor revision requested from European J. Appl. Math., arXiv:1908.01602}
}

@article{E2019multilevel,
  title={On multilevel {Picard} numerical approximations for high-dimensional nonlinear parabolic partial differential equations and high-dimensional nonlinear backward stochastic differential equations},
  author={E, Weinan and Hutzenthaler, Martin and Jentzen, Arnulf and Kruse, Thomas},
  journal={J. Sci. Comput.},
  fjournal={Journal of Scientific Computing},
  volume={79},
  number={3},
  pages={1534--1571},
  year={2019},
  publisher={Springer}
}

@article{Deveney2019,
abstract = {We propose a novel deep learning approach to efficiently perform Bayesian inference in partial differential equation (PDE) and integral equation models over potentially high-dimensional parameter spaces. The contributions of this paper are two-fold; the first is the introduction of a neural network algorithm for approximating the solutions of Fredholm and Volterra integral equations of the first and second kind. The second is the description of a deep surrogate model which allows for efficient sampling from a Bayesian posterior distribution in which the likelihood depends on the solutions of PDEs or integral equations. For the latter, our method relies on the approximation of parametric solutions by neural networks. This deep learning approach allows for parametric solutions to be approximated accurately in significantly higher dimensions than is possible using classical techniques. These solutions are very cheap to evaluate, making Bayesian inference over large parameter spaces tractable for these models using Markov chain Monte Carlo. We demonstrate this method using two real-world examples; these include Bayesian inference in the PDE and integral equation case for an example from electrochemistry, and Bayesian inference of a functionvalued heat-Transfer parameter with applications in aviation.},
author = {Deveney, Teo and Mueller, Eike and Shardlow, Tony},
journal = {arXiv:1910.01547},
title = {{A deep surrogate approach to efficient Bayesian inversion in PDE and integral equation models}},
year = {2019}
}
@book{Kavallaris2018,
    AUTHOR = {Kavallaris, Nikos I. and Suzuki, Takashi},
     TITLE = {Non-local partial differential equations for engineering and
              biology},
    SERIES = {Mathematics for Industry (Tokyo)},
    VOLUME = {31},
 PUBLISHER = {Springer, Cham},
      YEAR = {2018},
     PAGES = {xix+300},
      ISBN = {978-3-319-67942-6; 978-3-319-67944-0},
   MRCLASS = {74-02 (35K55 35R09 80A99 91B02 92C17 92C45)},
  MRNUMBER = {3752137},
MRREVIEWER = {Corina-\c{S}tefania Drapaca},
       DOI = {10.1007/978-3-319-67944-0},
       URL = {https://doi.org/10.1007/978-3-319-67944-0},
}
	
@article{Alfaro2019,
    AUTHOR = {Alfaro, Matthieu and Veruete, Mario},
     TITLE = {Evolutionary branching via replicator-mutator equations},
   JOURNAL = {J. Dynam. Differential Equations},
  FJOURNAL = {Journal of Dynamics and Differential Equations},
    VOLUME = {31},
      YEAR = {2019},
    NUMBER = {4},
     PAGES = {2029--2052},
      ISSN = {1040-7294},
   MRCLASS = {92D15 (35B40 35K15 35K58 35Q92)},
  MRNUMBER = {4028562},
       DOI = {10.1007/s10884-018-9692-9},
       URL = {https://doi.org/10.1007/s10884-018-9692-9},
}
@article{Sachs2008,
abstract = {Jump-diffusion models for the pricing of derivatives lead under certain assumptions to partial integro-differential equations (PIDE). Such a PIDE typically involves a convection term and a non-local integral. We transform the PIDE to eliminate the convection term, discretize it implicitly, and use finite differences on a uniform grid. The resulting dense linear system exhibits so much structure that it can be solved very efficiently by a circulant preconditioned conjugate gradient method. Therefore, this fully implicit scheme requires only on the order of O (n log n) operations. Second order accuracy is obtained numerically on the whole computational domain for Merton's model.},
author = {Sachs, E.W. and Strauss, A.K.},
doi = {10.1016/j.apnum.2007.11.002},
file = {:Users/victorboussange/Downloads/1-s2.0-S0168927407001663-main.pdf:pdf},
issn = {01689274},
journal = {Applied Numerical Mathematics},
keywords = {Conjugate Gradient method,L{\'{e}}vy process,Partial integro-differential equations,Toeplitz matrices},
mendeley-groups = {Complexity/Project_Proposal/stochanal/finance},
month = {nov},
number = {11},
pages = {1687--1703},
title = {{Efficient solution of a partial integro-differential equation in finance}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0168927407001663},
volume = {58},
year = {2008}
}
@article{Kou2000,
author = {Kou, S. G.},
title = {{A Jump-Diffusion Model for Option Pricing}},
journal = {Manag. Sci.},
volume = {48},
number = {8},
pages = {1086-1101},
year = {2002},
doi = {10.1287/mnsc.48.8.1086.166},
URL = {https://doi.org/10.1287/mnsc.48.8.1086.166},
eprint = {https://doi.org/10.1287/mnsc.48.8.1086.166},
abstract = {Brownian motion and normal distribution have been widely used in the Black–Scholes option-pricing framework to model the return of assets. However, two puzzles emerge from many empirical investigations: the leptokurtic feature that the return distribution of assets may have a higher peak and two (asymmetric) heavier tails than those of the normal distribution, and an empirical phenomenon called “volatility smile” in option markets. To incorporate both of them and to strike a balance between reality and tractability, this paper proposes, for the purpose of option pricing, a double exponential jump-diffusion model. In particular, the model is simple enough to produce analytical solutions for a variety of option-pricing problems, including call and put options, interest rate derivatives, and path-dependent options. Equilibrium analysis and a psychological interpretation of the model are also presented. }
}
@article {Gan2020,
    AUTHOR = {Gan, Xiaoting and Yang, Ying and Zhang, Kun},
     TITLE = {A robust numerical method for pricing {A}merican options under
              {K}ou's jump-diffusion models based on penalty method},
   JOURNAL = {J. Appl. Math. Comput.},
  FJOURNAL = {Journal of Applied Mathematics and Computing},
    VOLUME = {62},
      YEAR = {2020},
    NUMBER = {1--2},
     PAGES = {1--21},
      ISSN = {1598-5865},
   MRCLASS = {65M06 (60J76 65M12 65M32 91G60)},
  MRNUMBER = {4056888},
       DOI = {10.1007/s12190-019-01270-1},
       URL = {https://doi.org/10.1007/s12190-019-01270-1},
}
@article {Huang2013,
    AUTHOR = {Huang, Jian and Cen, Zhongdi and Le, Anbo},
     TITLE = {A finite difference scheme for pricing {A}merican put options
              under {K}ou's jump-diffusion model},
   JOURNAL = {J. Funct. Spaces Appl.},
  FJOURNAL = {Journal of Function Spaces and Applications},
      YEAR = {2013},
     PAGES = {Article No. 651573, 11 pp.},
      ISSN = {0972-6802},
   MRCLASS = {91G20},
  MRNUMBER = {3028547},
       DOI = {10.1155/2013/651573},
       URL = {https://doi.org/10.1155/2013/651573},
}
@article{Henry-Labordere2012,
abstract = {The purpose of this paper is to design an algorithm for the computation of the counterparty risk which is competitive in regards of a brute force "Monte-Carlo of Monte-Carlo" method (with nested simulations). This is achieved using marked branching diffusions describing a Galton-Watson random tree. Such an algorithm leads at the same time to a computation of the (bilateral) counterparty risk when we use the default-risky or counterparty-riskless option values as mark-to-market. Our method is illustrated by various numerical examples.},
archivePrefix = {arXiv},
arxivId = {1203.2369},
author = {Henry-Labord{\`e}re, Pierre},
eprint = {1203.2369},
file = {:Users/victorboussange/Downloads/1203.2369.pdf:pdf},
pages = {17 pp.},
title = {{Counterparty Risk Valuation: A Marked Branching Diffusion Approach}},
url = {http://arxiv.org/abs/1203.2369},
year = {2012},
journal = {arXiv:1203.2369}
}
@article{Oechssler2001,
    AUTHOR = {Oechssler, J\"{o}rg and Riedel, Frank},
     TITLE = {Evolutionary dynamics on infinite strategy spaces},
   JOURNAL = {Econom. Theory},
  FJOURNAL = {Economic Theory},
    VOLUME = {17},
      YEAR = {2001},
    NUMBER = {1},
     PAGES = {141--162},
      ISSN = {0938-2259},
   MRCLASS = {91A22 (91A13)},
  MRNUMBER = {1808098},
MRREVIEWER = {Ross Cressman},
       DOI = {10.1007/PL00004092},
       URL = {https://doi.org/10.1007/PL00004092},
}
@article{Bellman,
author = {Bellman, Richard},
doi = {10.1126/science.153.3731.34},
file = {:Users/victorboussange/Downloads/bellman1966.pdf:pdf},
issn = {0036-8075},
journal = {Science},
mendeley-groups = {Complexity/Project_Proposal/stochanal/intro},
number = {3731},
pages = {34--37},
title = {{Dynamic Programming}},
url = {https://www.sciencemag.org/lookup/doi/10.1126/science.153.3731.34},
volume = {153},
year = {1966}
}

@book {Bellman1957,
    AUTHOR = {Bellman, Richard},
     TITLE = {Dynamic Programming},
    SERIES = {Princeton Landmarks in Mathematics},
      NOTE = {Reprint of the 1957 edition},
 PUBLISHER = {Princeton University Press, Princeton, NJ},
      YEAR = {2010},
     PAGES = {xxx+340},
      ISBN = {978-0-691-14668-3},
   MRCLASS = {90-01 (49L20 90C39)},
  MRNUMBER = {2641641},
}


@article{Nordbotten2018,
    AUTHOR = {Nordbotten, Jan M. and Levin, Simon A. and Szathm\'{a}ry, E\"{o}rs and
              Stenseth, Nils C.},
     TITLE = {Ecological and evolutionary dynamics of interconnectedness and
              modularity},
   JOURNAL = {Proc. Natl. Acad. Sci. USA},
  FJOURNAL = {Proceedings of the National Academy of Sciences of the United
              States of America},
    VOLUME = {115},
      YEAR = {2018},
    NUMBER = {4},
     PAGES = {750--755},
      ISSN = {0027-8424},
   MRCLASS = {92D40 (37N25)},
  MRNUMBER = {3760513},
       DOI = {10.1073/pnas.1716078115},
       URL = {https://doi.org/10.1073/pnas.1716078115},
}
	
@article{Nordbotten2016,
  author = {Nordbotten, Jan M. and Stenseth, Nils C.},
  doi = {10.1073/pnas.1525395113},
   JOURNAL = {Proc. Natl. Acad. Sci. USA},
  mendeley-groups = {Complexity/Project_Proposal/cas_de/Adaptive Dynamics,Complexity/Project_Proposal/stochanal/biology},
  number = {7},
  pages = {1847--1852},
  title = {{Asymmetric ecological conditions favor Red-Queen type of continued evolution over stasis}},
  volume = {113},
  year = {2016}
}
@article{Nordbotten2020,
abstract = {In this paper, we establish the explicit connection between deterministic trait-based population-level models (in the form of partial differential equations) and species-level models (in the form of ordinary differential equations), in the context of eco-evolutionary systems. In particular, by starting from a population-level model of density distributions in trait space, we derive what amounts to an extension of the typical models at the species level known from adaptive dynamics literature, to account not only for abundance and mean trait values, but also explicitly for trait variances. Thus, we arrive at an explicitly polymorphic model at the species level. The derivations make precise the relationship between the parameters in the two classes of models and allow us to distinguish between notions of fitness on the population and species levels. Through a formal stability analysis, we see that exponential growth of an eigenvalue in the trait covariance matrix corresponds to a breakdown of the underlying assumptions of the species-level model. In biological terms, this may be interpreted as a speciation event: that is, we obtain an explicit notion of the blow-up of the variance of (possibly a linear combination of) traits as a precursor to speciation. Moreover, since evolutionary volatility of the mean trait value is proportional to trait variance, this provides a notion that species at the cusp of speciation are also the most adaptive. We illustrate these concepts and considerations using a numerical simulation.},
author = {Nordbotten, Jan Martin and Bokma, Folmer and Hermansen, Jo Skeie and Stenseth, Nils Chr},
doi = {10.1098/rsos.200321},
file = {:Users/victorboussange/Downloads/rsos.200321.pdf:pdf},
issn = {2054-5703},
journal = {R. Soc. Open Sci.},
fjournal = {Royal Society Open Science},
keywords = {biomathematics,mathematical,theoretical biology},
mendeley-groups = {Complexity/Project_Proposal/nordbotten style,Complexity/Project_Proposal/stochanal/biology},
number = {8},
pages = {Article No. 200321, 20 pp.},
title = {{The dynamics of trait variance in multi-species communities}},
url = {https://royalsocietypublishing.org/doi/10.1098/rsos.200321},
volume = {7},
year = {2020}
}
@article{Champagnat2008,
abstract = {We are interested in modelling Darwinian evolution, resulting from the interplay of phenotypic variation and natural selection through ecological interactions. Our models are rooted in the microscopic, stochastic description of a population of discrete individuals characterized by one or several adaptive traits. The population is modelled as a stochastic point process whose generator captures the probabilistic dynamics over continuous time of birth, mutation, and death, as influenced by each individual's trait values, and interactions between individuals. An offspring usually inherits the trait values of her progenitor, except when a mutation causes the offspring to take an instantaneous mutation step at birth to new trait values. We look for tractable large population approximations. By combining various scalings on population size, birth and death rates, mutation rate, mutation step, or time, a single microscopic model is shown to lead to contrasting macroscopic limits of a different nature: deterministic, in the form of ordinary, integro-, or partial differential equations, or probabilistic, like stochastic partial differential equations or superprocesses. In the limit of rare mutations, we show that a possible approximation is a jump process, justifying rigorously the so-called trait substitution sequence. We thus unify different points of view concerning mutation-selection evolutionary models.},
author = {Champagnat, Nicolas and Ferri{\`{e}}re, R{\'{e}}gis and M{\'{e}}l{\'{e}}ard, Sylvie},
doi = {10.1080/15326340802437710},
file = {:Users/victorboussange/Library/Application Support/Mendeley Desktop/Downloaded/Champagnat, Ferri{\`{e}}re, M{\'{e}}l{\'{e}}ard - 2008 - From Individual Stochastic Processes to Macroscopic Models in Adaptive Evolution.pdf:pdf},
isbn = {1532634080},
issn = {1532-6349},
journal = {Stochastic Models},
keywords = {Adaptive dynamics,Birth-death-mutation-competition point process,Darwinian evolution,Fitness,Mutation-selection dynamics,Nonlinear integro-differential equations,Nonlinear partial differential equations,Nonlinear superprocesses},
mendeley-groups = {Complexity/Project_Proposal/cas_de/ABM to eq,Complexity/Project_Proposal/stochanal/biology},
month = {nov},
number = {sup1},
pages = {2--44},
title = {{From Individual Stochastic Processes to Macroscopic Models in Adaptive Evolution}},
url = {https://www.tandfonline.com/doi/full/10.1080/15326340802437710},
volume = {24},
year = {2008}
}
@article{Han2018,
    AUTHOR = {Han, Jiequn and Jentzen, Arnulf and E, Weinan},
     TITLE = {Solving high-dimensional partial differential equations using
              deep learning},
   JOURNAL = {Proc. Natl. Acad. Sci. USA},
  FJOURNAL = {Proceedings of the National Academy of Sciences of the United
              States of America},
    VOLUME = {115},
      YEAR = {2018},
    NUMBER = {34},
     PAGES = {8505--8510},
      ISSN = {0027-8424},
   MRCLASS = {35K55 (68T05 91A26 92C20)},
  MRNUMBER = {3847747},
       DOI = {10.1073/pnas.1718942115},
       URL = {https://doi.org/10.1073/pnas.1718942115},
}
@article{Pajaro2017,
    AUTHOR = {P\'{a}jaro, Manuel and Alonso, Antonio A. and Otero-Muras, Irene
              and V\'{a}zquez, Carlos},
     TITLE = {Stochastic modeling and numerical simulation of gene
              regulatory networks with protein bursting},
   JOURNAL = {J. Theoret. Biol.},
  FJOURNAL = {Journal of Theoretical Biology},
    VOLUME = {421},
      YEAR = {2017},
     PAGES = {51--70},
      ISSN = {0022-5193},
   MRCLASS = {92D10},
  MRNUMBER = {3638113},
       DOI = {10.1016/j.jtbi.2017.03.017},
       URL = {https://doi.org/10.1016/j.jtbi.2017.03.017},
}
	
@article{RUBINSTEIN1992,
    AUTHOR = {Rubinstein, Jacob and Sternberg, Peter},
     TITLE = {Nonlocal reaction-diffusion equations and nucleation},
   JOURNAL = {IMA J. Appl. Math.},
  FJOURNAL = {IMA Journal of Applied Mathematics},
    VOLUME = {48},
      YEAR = {1992},
    NUMBER = {3},
     PAGES = {249--264},
      ISSN = {0272-4960},
   MRCLASS = {35K57 (35C20 82C24)},
  MRNUMBER = {1167735},
MRREVIEWER = {Reinhard Redlinger},
       DOI = {10.1093/imamat/48.3.249},
       URL = {https://doi.org/10.1093/imamat/48.3.249},
}
@article{Amadori2007,
    AUTHOR = {Amadori, Anna Lisa},
     TITLE = {Obstacle problem for nonlinear integro-differential equations
              arising in option pricing},
   JOURNAL = {Ric. Mat.},
  FJOURNAL = {Ricerche di Matematica. A Journal of Pure and Applied
              Mathematics},
    VOLUME = {56},
      YEAR = {2007},
    NUMBER = {1},
     PAGES = {1--17},
      ISSN = {0035-5038},
   MRCLASS = {49L25 (35K85 91B24)},
  MRNUMBER = {2330346},
MRREVIEWER = {Cyril Imbert},
       DOI = {10.1007/s11587-007-0001-x},
       URL = {https://doi.org/10.1007/s11587-007-0001-x},
}
@article{Benth2001,
    AUTHOR = {Benth, Fred Espen and Karlsen, Kenneth Hvistendahl and
              Reikvam, Kristin},
     TITLE = {Optimal portfolio selection with consumption and nonlinear
              integro-differential equations with gradient constraint: a
              viscosity solution approach},
   JOURNAL = {Finance Stoch.},
  FJOURNAL = {Finance and Stochastics},
    VOLUME = {5},
      YEAR = {2001},
    NUMBER = {3},
     PAGES = {275--303},
      ISSN = {0949-2984},
   MRCLASS = {91B28 (45K05 49L25)},
  MRNUMBER = {1849422},
       DOI = {10.1007/PL00013538},
       URL = {https://doi.org/10.1007/PL00013538},
}
@article{Stoleriu2011,
    AUTHOR = {Stoleriu, Iulian},
     TITLE = {Non-local models for solid-solid phase transitions},
   JOURNAL = {ROMAI J.},
  FJOURNAL = {ROMAI Journal},
    VOLUME = {7},
      YEAR = {2011},
    NUMBER = {1},
     PAGES = {157--170},
      ISSN = {1841-5512},
   MRCLASS = {35K59 (35R09 45K05 80A22)},
  MRNUMBER = {2833638},
}
@article{Banerjee2021,
abstract = {Dynamics of human populations can be affected by various socio-economic factors through their influence on the natality and mortality rates, and on the migration intensity and directions. In this work we study an economic–demographic model which takes into account the dependence of the wealth production rate on the available resources. In the case of nonlocal consumption of resources, the homogeneous-in-space wealth–population distribution is replaced by a periodic-inspace distribution for which the total wealth increases. For the global consumption of resources, if the wealth redistribution is small enough, then the homogeneous distribution is replaced by a heterogeneous one with a single wealth accumulation center. Thus, economic and demographic characteristics of nonlocal and global economies can be quite different in comparison with the local economy.},
author = {Banerjee, Malay and Petrovskii, Sergei V. and Volpert, Vitaly},
doi = {10.3390/math9040351},
file = {:Users/victorboussange/Library/Application Support/Mendeley Desktop/Downloaded/Banerjee, Petrovskii, Volpert - 2021 - Nonlocal reaction–diffusion models of heterogeneous wealth distribution.pdf:pdf},
issn = {22277390},
journal = {Mathematics},
keywords = {Human population dynamics,Nonlocal consumption of resources,Spatial patterns,Wealth distribution},
mendeley-groups = {Complexity/Project_Proposal/stochanal/economics},
number = {4},
pages = {Article No. 351, 18 pp.},
title = {{Nonlocal reaction-diffusion models of heterogeneous wealth distribution}},
volume = {9},
year = {2021}
}
@book{Tankov2003,
    AUTHOR = {Cont, Rama and Tankov, Peter},
     TITLE = {Financial modelling with jump processes},
    SERIES = {Chapman \& Hall/CRC Financial Mathematics Series},
 PUBLISHER = {Chapman \& Hall/CRC, Boca Raton, FL},
      YEAR = {2004},
     PAGES = {xvi+535},
      ISBN = {1-5848-8413-4},
   MRCLASS = {91-02 (60J75 91B28 91B84)},
  MRNUMBER = {2042661},
}
@article{Villa2021,
    AUTHOR = {Villa, Chiara and Chaplain, Mark A. J. and Lorenzi, Tommaso},
     TITLE = {Evolutionary dynamics in vascularised tumours under
              chemotherapy: mathematical modelling, asymptotic analysis and
              numerical simulations},
   JOURNAL = {Vietnam J. Math.},
  FJOURNAL = {Vietnam Journal of Mathematics},
    VOLUME = {49},
      YEAR = {2021},
    NUMBER = {1},
     PAGES = {143--167},
      ISSN = {2305-221X},
   MRCLASS = {92D15 (35Q92 45K05 92C50)},
  MRNUMBER = {4236968},
       DOI = {10.1007/s10013-020-00445-9},
       URL = {https://doi.org/10.1007/s10013-020-00445-9},
}
@InProceedings{glorot2010,
  title = 	 {Understanding the difficulty of training deep feedforward neural networks},
  author = 	 {Glorot, Xavier and Bengio, Yoshua},
  booktitle = 	 {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {249--256},
  year = 	 {2010},
  editor = 	 {Teh, Yee Whye and Titterington, Mike},
  volume = 	 {9},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Chia Laguna Resort, Sardinia, Italy},
  month = 	 {13--15 May},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf},
  url = 	 {https://proceedings.mlr.press/v9/glorot10a.html},
  abstract = 	 {Whereas before 2006 it appears that deep multi-layer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future.  We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1.  Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence.}
}
@article{Roques2016,
abstract = {We propose and develop a general approach based on reaction-diffusion equations for modelling a species dynamics in a realistic two-dimensional (2D) landscape crossed by linear one-dimensional (1D) corridors, such as roads, hedgerows or rivers. Our approach is based on a hybrid “2D/1D model”, i.e, a system of 2D and 1D reaction-diffusion equations with homogeneous coefficients, in which each equation describes the population dynamics in a given 2D or 1D element of the landscape. Using the example of the range expansion of the tiger mosquito Aedes albopictus in France and its main highways as 1D corridors, we show that the model can be fitted to realistic observation data. We develop a mechanistic-statistical approach, based on the coupling between a model of population dynamics and a probabilistic model of the observation process. This allows us to bridge the gap between the data (3 levels of infestation, at the scale of a French department) and the output of the model (population densities at each point of the landscape), and to estimate the model parameter values using a maximum-likelihood approach. Using classical model comparison criteria, we obtain a better fit and a better predictive power with the 2D/1D model than with a standard homogeneous reaction-diffusion model. This shows the potential importance of taking into account the effect of the corridors (highways in the present case) on species dynamics. With regard to the particular case of A. albopictus, the conclusion that highways played an important role in species range expansion in mainland France is consistent with recent findings from the literature.},
author = {Roques, Lionel and Bonnefon, Olivier},
doi = {10.1371/journal.pone.0151217},
editor = {Jin, Zhen},
file = {:Users/victorboussange/Downloads/pone.0151217.pdf:pdf},
issn = {1932-6203},
journal = {PLoS ONE},
mendeley-groups = {Complexity/Project_Proposal/stochanal/biology},
number = {3},
pages = {Article No. e0151217, 20 pp.},
pmid = {26986201},
title = {{Modelling Population Dynamics in Realistic Landscapes with Linear Elements: A Mechanistic-Statistical Reaction-Diffusion Approach}},
url = {https://dx.plos.org/10.1371/journal.pone.0151217},
volume = {11},
year = {2016}
}
@article {Weinan2021,
    AUTHOR = {E, Weinan and Hutzenthaler, Martin and Jentzen, Arnulf and
              Kruse, Thomas},
     TITLE = {Multilevel {P}icard iterations for solving smooth semilinear
              parabolic heat equations},
   JOURNAL = {Partial Differ. Equ. Appl.},
  FJOURNAL = {Partial Differential Equations and Applications},
    VOLUME = {2},
      YEAR = {2021},
    NUMBER = {6},
     PAGES = {Article No. 80, 31 pp.},
      ISSN = {2662-2963},
   MRCLASS = {65M75},
  MRNUMBER = {4338044},
       DOI = {10.1007/s42985-021-00089-5},
       URL = {https://doi.org/10.1007/s42985-021-00089-5},
}
@article {Weinan2019,
    AUTHOR = {E, Weinan and Hutzenthaler, Martin and Jentzen, Arnulf and
              Kruse, Thomas},
     TITLE = {On multilevel {P}icard numerical approximations for
              high-dimensional nonlinear parabolic partial differential
              equations and high-dimensional nonlinear backward stochastic
              differential equations},
   JOURNAL = {J. Sci. Comput.},
  FJOURNAL = {Journal of Scientific Computing},
    VOLUME = {79},
      YEAR = {2019},
    NUMBER = {3},
     PAGES = {1534--1571},
      ISSN = {0885-7474},
   MRCLASS = {65C05 (65C30 65M99 91G60)},
  MRNUMBER = {3946468},
MRREVIEWER = {Andr\'{e} S\"{u}\ss },
       DOI = {10.1007/s10915-018-00903-0},
       URL = {https://doi.org/10.1007/s10915-018-00903-0},
}
@article {Hutzenthaler2020,
    AUTHOR = {Hutzenthaler, Martin and Jentzen, Arnulf and Kruse, Thomas and
              Nguyen, Tuan Anh and von Wurstemberger, Philippe},
     TITLE = {Overcoming the curse of dimensionality in the numerical
              approximation of semilinear parabolic partial differential
              equations},
   JOURNAL = {Proc. A.},
  FJOURNAL = {Proceedings A},
    VOLUME = {476},
      YEAR = {2020},
    NUMBER = {2244},
     PAGES = {Article No. 20190630, 25 pp.},
      ISSN = {1364-5021},
   MRCLASS = {65N75 (35K58 65C05)},
  MRNUMBER = {4203091},
       DOI = {10.1098/rspa.2019.0630},
       URL = {https://doi.org/10.1098/rspa.2019.0630},
}
@article {Doebeli2010,
    AUTHOR = {Doebeli, Michael and Ispolatov, Iaroslav},
     TITLE = {Complexity and diversity},
   JOURNAL = {Science},
  FJOURNAL = {American Association for the Advancement of Science. Science},
    VOLUME = {328},
      YEAR = {2010},
    NUMBER = {5977},
     PAGES = {494--497},
      ISSN = {0036-8075},
   MRCLASS = {92B05 (62P10)},
  MRNUMBER = {2662081},
       DOI = {10.1126/science.1187468},
       URL = {https://doi.org/10.1126/science.1187468},
}
@article {Beck2020b,
    AUTHOR = {Beck, Christian and Hornung, Fabian and Hutzenthaler, Martin
              and Jentzen, Arnulf and Kruse, Thomas},
     TITLE = {Overcoming the curse of dimensionality in the numerical
              approximation of {A}llen-{C}ahn partial differential equations
              via truncated full-history recursive multilevel {P}icard
              approximations},
   JOURNAL = {J. Numer. Math.},
  FJOURNAL = {Journal of Numerical Mathematics},
    VOLUME = {28},
      YEAR = {2020},
    NUMBER = {4},
     PAGES = {197--222},
      ISSN = {1570-2820},
   MRCLASS = {60H30 (65C05 65M75)},
  MRNUMBER = {4191733},
       DOI = {10.1515/jnma-2019-0074},
       URL = {https://doi.org/10.1515/jnma-2019-0074},
}

@article{duchi2011adaptive,
  author  = {John Duchi and Elad Hazan and Yoram Singer},
  title   = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
  journal = {J. Mach. Learn. Res.},
  fjournal = {Journal of Machine Learning Research},
  year    = {2011},
  volume  = {12},
  number  = {61},
  pages   = {2121-2159},
  url     = {http://jmlr.org/papers/v12/duchi11a.html}
}


@InProceedings{ioffe2015batch,
  title = 	 {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author = 	 {Ioffe, Sergey and Szegedy, Christian},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {448--456},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/ioffe15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/ioffe15.html},
  abstract = 	 {Training Deep Neural Networks is complicated by the fact that the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a stateof-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.}
}


@article {cox2013pathwise,
    AUTHOR = {Cox, Sonja and van Neerven, Jan},
     TITLE = {Pathwise {H}\"{o}lder convergence of the implicit-linear {E}uler
              scheme for semi-linear {SPDE}s with multiplicative noise},
   JOURNAL = {Numer. Math.},
  FJOURNAL = {Numerische Mathematik},
    VOLUME = {125},
      YEAR = {2013},
    NUMBER = {2},
     PAGES = {259--345},
      ISSN = {0029-599X},
   MRCLASS = {65C30 (60H15 60H35 65J08)},
  MRNUMBER = {3101829},
MRREVIEWER = {Edward J. Allen},
       DOI = {10.1007/s00211-013-0538-4},
}
@article {gyongy2003splitting,
    AUTHOR = {Gy\"{o}ngy, Istv\'{a}n and Krylov, Nicolai},
     TITLE = {On the splitting-up method and stochastic partial differential
              equations},
   JOURNAL = {Ann. Probab.},
  FJOURNAL = {The Annals of Probability},
    VOLUME = {31},
      YEAR = {2003},
    NUMBER = {2},
     PAGES = {564--591},
      ISSN = {0091-1798},
   MRCLASS = {60H15 (65C30 93E11)},
  MRNUMBER = {1964941},
MRREVIEWER = {Frederi G. Viens},
       DOI = {10.1214/aop/1048516528},
}
@article {hochbruck2005explicit,
    AUTHOR = {Hochbruck, Marlis and Ostermann, Alexander},
     TITLE = {Explicit exponential {R}unge--{K}utta methods for semilinear
              parabolic problems},
   JOURNAL = {SIAM J. Numer. Anal.},
  FJOURNAL = {SIAM Journal on Numerical Analysis},
    VOLUME = {43},
      YEAR = {2005},
    NUMBER = {3},
     PAGES = {1069--1090},
      ISSN = {0036-1429},
   MRCLASS = {65M20 (65L06)},
  MRNUMBER = {2177796},
MRREVIEWER = {Inmaculada Higueras},
       DOI = {10.1137/040611434},
}

@article{beck2018solving,
	title={Solving the {K}olmogorov {PDE} by means of deep learning},
	author={Beck, Christian and Becker, Sebastian and Grohs, Philipp and Jaafari, Nor and Jentzen, Arnulf},
	journal={J. Sci. Comput.},
	fjournal={Journal of Scientific Computing},
	volume          = {88},
	year={2021}, 
	pages={Article No. 73, 28 pp.}
}

@article{yuan2022apinn,
title = {{A}-{PINN}: Auxiliary physics informed neural networks for forward and inverse problems of nonlinear integro-differential equations},
journal = {J. Comput. Phys.},
fjournal = {Journal of Computational Physics},
pages = {Article No. 111260},
note={Early access version available online},
year = {2022},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2022.111260},
url = {https://www.sciencedirect.com/science/article/pii/S0021999122003229},
author = {Lei Yuan and Yi-Qing Ni and Xiang-Yun Deng and Shuo Hao},
keywords = {Physics informed neural network (PINN), Auxiliary physics informed neural network (A-PINN), Integro-differential equations (IDEs), Deep learning, Multi-output neural network}
}
@InProceedings{frey2022deep,
author="Frey, R{\"u}diger
and K{\"o}ck, Verena",
editor="Corazza, Marco
and Perna, Cira
and Pizzi, Claudio
and Sibillo, Marilena",
title="Deep Neural Network Algorithms for Parabolic {PIDE}s and Applications in Insurance Mathematics",
booktitle="Mathematical and Statistical Methods for Actuarial Sciences and Finance",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="272--277",
abstract="In recent years a large literature on deep learning based methods for the numerical solution partial differential equations has emerged; results for integro-differential equations on the other hand are scarce. In this short paper we study deep neural network algorithms for solving linear parabolic partial integro-differential equations with boundary conditions in high dimension. To show the viability of our approach we discuss a test case study from insurance.",
isbn="978-3-030-99638-3"
}

@article{fu2022unsupervised,
author = {Weilong Fu and Ali Hirsa},
title = {An unsupervised deep learning approach to solving partial integro-differential equations},
journal = {Quantitative Finance},
note={Early access version available online},
pages = {14 pp.},
year  = {2022},
publisher = {Routledge},
doi = {10.1080/14697688.2022.2057870},
URL = { 
        https://doi.org/10.1080/14697688.2022.2057870
    
},
eprint = { 
        https://doi.org/10.1080/14697688.2022.2057870
    
}
}
@article{alaradi2019extensions,
archivePrefix = {arXiv},
  author = {Al-Aradi, Ali and Correia, Adolfo and Naiff, Danilo de Frietas and Jardim, Gabriel and Saporito, Yuri},
pages = {27 pp.},
  title = {Extensions of the Deep {G}alerkin Method},
url = {http://arxiv.org/abs/1912.01455},
year = {2019},
journal = {arXiv:1912.01455},
}
@article{delia2020numerical, 
  title={Numerical methods for nonlocal and fractional models}, 
  volume={29},
 DOI={10.1017/S096249292000001X},
 journal={Acta Numerica},
 publisher={Cambridge University Press},
 author={D'Elia, Marta and Du, Qiang and Glusa, Christian and Gunzburger, Max and Tian, Xiaochuan and Zhou, Zhi},
 year={2020},
 pages={1-124}
 }
 @article{castro2021deep,
archivePrefix = {arXiv},
  author = {Castro, Javier},
pages = {28 pp.},
  title = {Deep Learning Schemes For Parabolic Nonlocal Integro-Differential Equations},
  url = {https://arxiv.org/abs/2103.15008},
year = {2021},
journal = {arXiv:2103.15008},
}
@article{guo2022monte,
archivePrefix = {arXiv},
  author = {Guo, Ling and Wu, Hao and Yu, Xiaochen and Zhou, Tao},
pages = {18 pp.},
  title = {{M}onte {C}arlo {PINN}s: deep learning approach for forward and inverse problems involving high dimensional fractional partial differential equations},
  url = {https://arxiv.org/abs/2203.08501},
year = {2022},
journal = {arXiv:2203.08501},
}

@article{pang2019fpinns,
author = {Pang, Guofei and Lu, Lu and Karniadakis, George Em},
title = {{fPINN}s: Fractional Physics-Informed Neural Networks},
journal = {SIAM Journal on Scientific Computing},
volume = {41},
number = {4},
pages = {A2603-A2626},
year = {2019},
doi = {10.1137/18M1229845},

URL = { 
        https://doi.org/10.1137/18M1229845
    
},
eprint = { 
        https://doi.org/10.1137/18M1229845
    
}
}
@article{lu2021deepxde,
author = {Lu, Lu and Meng, Xuhui and Mao, Zhiping and Karniadakis, George Em},
title = {{DeepXDE}: A Deep Learning Library for Solving Differential Equations},
journal = {SIAM Review},
volume = {63},
number = {1},
pages = {208-228},
year = {2021},
doi = {10.1137/19M1274067},

URL = { 
        https://doi.org/10.1137/19M1274067
    
},
eprint = { 
        https://doi.org/10.1137/19M1274067
    
}
}


@article{raissi2019physics,
  title={Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George E},
   JOURNAL = {J. Comput. Phys.},
  FJOURNAL = {Journal of Computational Physics},
  volume={378},
  pages={686--707},
  year={2019},
  publisher={Elsevier}
}

@article{Sirignano2018dgm,
  title={{DGM}: A deep learning algorithm for solving partial differential equations},
  author={Sirignano, Justin and Spiliopoulos, Konstantinos},
  journal={J. Comput. Phys.},
  fjournal={Journal of Computational Physics},
  volume={375},
  pages={1339--1364},
  year={2018},
  publisher={Elsevier}
}

@article{frey2021deep,
archivePrefix = {arXiv},
  author = {Frey, R{\"u}diger and K{\"o}ck, Verena},
pages = {24 pp.},
  title = {Deep Neural Network Algorithms for Parabolic {PIDE}s and Applications in Insurance Mathematics},
  url = {https://arxiv.org/abs/2109.11403},
year = {2021},
journal = {arXiv:2109.11403},
}

@article{hure2020deep,
  author          = {C{\^o}me Hur{\'e} and Huy{\^e}n Pham and Xavier Warin},
  journal         = {Math. Comp.},
  fjournal = {Mathematics of Computation},
  title           = {Deep backward schemes for high-dimensional nonlinear {PDE}s},
  volume          = {89},
  year            = {2020},
  pages = {1547-1579}
}


@Article{chen2020comparison,
author = {Jingrun Chen and Rui Du and Keke Wu},
title = {A Comparison Study of Deep {G}alerkin Method and Deep {R}itz Method for Elliptic Problems with Different Boundary Conditions},
fjournal = {Communications in Mathematical Research },
journal = {Comm. Math. Res.},
year = {2020},
volume = {36},
number = {3},
pages = {354--376},
issn = {2707-8523},
doi = {https://doi.org/10.4208/cmr.2020-0051},
url = {http://global-sci.org/intro/article_detail/cmr/17853.html}
}

@article{e2018deep,
  title={The {D}eep {Ritz} method: {A} deep learning-based numerical algorithm for solving variational problems},
  author={E, Weinan and Yu, Bing},
  fjournal={Communications in Mathematics and Statistics},
  journal={Commun. Math. Stat.},
  volume={6},
  number={1},
  pages={1--12},
  year={2018},
  publisher={Springer}
}


@Article{liao2021deep,
author = {Yulei Liao and Pingbing Ming},
title = {Deep {N}itsche Method: Deep {R}itz Method with Essential Boundary Conditions},
journal = {Comm. Comput. Phys.},
fjournal = {Communications in Computational Physics},
year = {2021},
volume = {29},
number = {5},
pages = {1365--1384},
abstract = {

We propose a new method to deal with the essential boundary conditions
encountered in the deep learning-based numerical solvers for partial differential equations. The trial functions representing by deep neural networks are non-interpolatory,
which makes the enforcement of the essential boundary conditions a nontrivial matter. Our method resorts to Nitsche's variational formulation to deal with this difficulty, which is consistent, and does not require significant extra computational costs.
We prove the error estimate in the energy norm and illustrate the method on several
representative problems posed in at most 100 dimension.
},
issn = {1991-7120},
doi = {https://doi.org/10.4208/cicp.OA-2020-0219},
url = {http://global-sci.org/intro/article_detail/cicp/18717.html}
}


@article{lagaris1998artificial,
  title={Artificial neural networks for solving ordinary and partial differential equations},
  author={Lagaris, Isaac E and Likas, Aristidis and Fotiadis, Dimitrios I},
  journal={IEEE Trans. Neural Netw.},
  fjournal={IEEE Transactions on Neural Networks},
  volume={9},
  number={5},
  pages={987--1000},
  year={1998},
  publisher={IEEE}
}

@ARTICLE{mcfall2009artificial,
  author={McFall, Kevin Stanley and Mahan, James Robert},
  journal={IEEE Trans. Neural Netw.},
  fjournal={IEEE Transactions on Neural Networks}, 
  title={Artificial Neural Network Method for Solution of Boundary Value Problems With Exact Satisfaction of Arbitrary Boundary Conditions}, 
  year={2009},
  volume={20},
  number={8},
  pages={1221-1233},
  doi={10.1109/TNN.2009.2020735}}

@ARTICLE{lagaris2000neural,
  author={Lagaris, I.E. and Likas, A.C. and Papageorgiou, D.G.},
  journal={IEEE Trans. Neural Netw.},
  fjournal={IEEE Transactions on Neural Networks},
  title={Neural-network methods for boundary value problems with irregular boundaries},
  year={2000},
  volume={11},
  number={5},
  pages={1041-1049},
  doi={10.1109/72.870037}}

@article{sukumar2022exact,
title = {Exact imposition of boundary conditions with distance functions in physics-informed deep neural networks},
fjournal = {Computer Methods in Applied Mechanics and Engineering},
journal={Comput. Methods Appl. Mech. Engrg.},
volume = {389},
pages = {Article No. 114333},
year = {2022},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2021.114333},
url = {https://www.sciencedirect.com/science/article/pii/S0045782521006186},
author = {N. Sukumar and Ankit Srivastava},
keywords = {Deep learning, Meshfree method, Distance function, R-function, Transfinite interpolation, Exact geometry},
abstract = {In this paper, we introduce a new approach based on distance fields to exactly impose boundary conditions in physics-informed deep neural networks. The challenges in satisfying Dirichlet boundary conditions in meshfree and particle methods are well-known. This issue is also pertinent in the development of physics informed neural networks (PINN) for the solution of partial differential equations. We introduce geometry-aware trial functions in artificial neural networks to improve the training in deep learning for partial differential equations. To this end, we use concepts from constructive solid geometry (R-functions) and generalized barycentric coordinates (mean value potential fields) to construct ϕ(x), an approximate distance function to the boundary of a domain in Rd. To exactly impose homogeneous Dirichlet boundary conditions, the trial function is taken as ϕ(x) multiplied by the PINN approximation, and its generalization via transfinite interpolation is used to a priori satisfy inhomogeneous Dirichlet (essential), Neumann (natural), and Robin boundary conditions on complex geometries. In doing so, we eliminate modeling error associated with the satisfaction of boundary conditions in a collocation method and ensure that kinematic admissibility is met pointwise in a Ritz method. With this new ansatz, the training for the neural network is simplified: sole contribution to the loss function is from the residual error at interior collocation points where the governing equation is required to be satisfied. Numerical solutions are computed using strong form collocation and Ritz minimization. To convey the main ideas and to assess the accuracy of the approach, we present numerical solutions for linear and nonlinear boundary-value problems over convex and nonconvex polygonal domains as well as over domains with curved boundaries. Benchmark problems in one dimension for linear elasticity, advection-diffusion, and beam bending; and in two dimensions for the steady-state heat equation, Laplace equation, biharmonic equation (Kirchhoff plate bending), and the nonlinear Eikonal equation are considered. The construction of approximate distance functions using R-functions extends to higher dimensions, and we showcase its use by solving a Poisson problem with homogeneous Dirichlet boundary conditions over the four-dimensional hypercube. The proposed approach consistently outperforms a standard PINN-based collocation method, which underscores the importance of exactly (a priori) satisfying the boundary condition when constructing a loss function in PINN. This study provides a pathway for meshfree analysis to be conducted on the exact geometry without domain discretization.}
}

@Article{DarbonOsher2016,
  author  = {Darbon, J{\'e}r{\^o}me and Osher, Stanley},
  title   = {Algorithms for overcoming the curse of dimensionality for certain {H}amilton--{J}acobi equations arising in control theory and elsewhere},
   JOURNAL = {Res. Math. Sci.},
  FJOURNAL = {Research in the Mathematical Sciences},
  year    = {2016},
  volume  = {3},
  number  = {19},
  issn    = {2197-9847},
  doi     = {10.1186/s40687-016-0068-7},
}

@article{metropolis1949monte,
author = { Nicholas   Metropolis  and  S.   Ulam },
title = {The {M}onte {C}arlo Method},
fjournal = {Journal of the American Statistical Association},
journal={J. Amer. Statist. Assoc. },
volume = {44},
number = {247},
pages = {335-341},
year  = {1949},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.1949.10483310},
URL = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1949.10483310},
eprint = {https://www.tandfonline.com/doi/pdf/10.1080/01621459.1949.10483310}
}

@article{bauer1958monte,
 ISSN = {03684245},
 URL = {http://www.jstor.org/stable/2098715},
 author = {W. F. Bauer},
 fjournal = {Journal of the Society for Industrial and Applied Mathematics},
 journal = {J. Soc. Ind. Appl. Math.},
 number = {4},
 pages = {438--451},
 publisher = {Society for Industrial and Applied Mathematics},
 title = {The {M}onte {C}arlo Method},
 urldate = {2022-05-06},
 volume = {6},
 year = {1958}
}


@article{EHanJentzen2017,
  title={Deep learning-based numerical methods for high-dimensional parabolic partial differential equations and backward stochastic differential equations},
  author={E, Weinan and Han, Jiequn and Jentzen, Arnulf},
  fjournal={Communications in Mathematics and Statistics},
  journal={Commun. Math. Stat.},
  pages={349--380},
  year={2017},
  publisher={Springer},
  volume={5},
  number={4},
  issn= {2194-671X},
  doi={10.1007/s40304-017-0117-6},
}